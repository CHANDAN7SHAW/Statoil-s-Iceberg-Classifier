{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statoil's Iceberg Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Drifting icebergs present threats to navigation and activities in areas such as offshore of the East Coast of Canada.\n",
    "\n",
    "Currently, many institutions and companies use aerial reconnaissance and shore-based support to monitor environmental conditions and assess risks from icebergs. However, in remote areas with particularly harsh weather, these methods are not feasible, and the only viable monitoring option is via satellite.\n",
    "\n",
    "Statoil, an international energy company operating worldwide, has worked closely with companies like C-CORE. C-CORE have been using satellite data for over 30 years and have built a computer vision based surveillance system. To keep operations safe and efficient, Statoil is interested in getting a fresh new perspective on how to use machine learning to more accurately detect and discriminate against threatening icebergs as early as possible.\n",
    "\n",
    "In this competition, youâ€™re challenged to build an algorithm that automatically identifies if a remotely sensed target is a ship or iceberg. Improvements made will help drive the costs down for maintaining safe working conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will build a deep neural network that can recognize images with an greater accuracy and less loss function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural network:**\n",
    "                    A computational model that works in a similar way to the neurons in the human brain. \n",
    "                    Each neuron takes an input,performs some operations then passes the output to the following neuron.\n",
    "                    [Figure](http://cs231n.github.io/assets/nn1/neural_net2.jpeg)                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will be building a convolutional neural network that will be trained on thousand of trained images data, and later be able to measure on test data to evalute the Test loss and Test accuracy of the builded model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of building a Convolutional Neural Network always involves four major steps :-\n",
    "\n",
    "Step - 1 : Convolution\n",
    "\n",
    "Step - 2 : Pooling\n",
    "\n",
    "Step - 3 : Flattening\n",
    "\n",
    "Step - 4 : Full connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">I used **Keras** which is a simple frameworks where we can initialize the model and keep stacking the layers we want. It makes building deep neural networks very easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#First let me import **keras** using **Tensorflow** backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing Numpy and Pandas for data analysis...\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing SkLearn to split data into Train and Test dataset...\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let me import all the required **keras** packages using which i am going to build our **CNN** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation, Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading the data from json file...\n",
    "training_data=pd.read_json(\"Train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-27.878360999999998, -27.15416, -28.668615, -...</td>\n",
       "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
       "      <td>dfd5f913</td>\n",
       "      <td>43.9239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-12.242375, -14.920304999999999, -14.920363, ...</td>\n",
       "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
       "      <td>e25388fd</td>\n",
       "      <td>38.1562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-24.603676, -24.603714, -24.871029, -23.15277...</td>\n",
       "      <td>[-24.870956, -24.092632, -20.653963, -19.41104...</td>\n",
       "      <td>58b2aaa0</td>\n",
       "      <td>45.2859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-22.454607, -23.082819, -23.998013, -23.99805...</td>\n",
       "      <td>[-27.889421, -27.519794, -27.165262, -29.10350...</td>\n",
       "      <td>4cfc3a18</td>\n",
       "      <td>43.8306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-26.006956, -23.164886, -23.164886, -26.89116...</td>\n",
       "      <td>[-27.206915, -30.259186, -30.259186, -23.16495...</td>\n",
       "      <td>271f93f4</td>\n",
       "      <td>35.6256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              band_1  \\\n",
       "0  [-27.878360999999998, -27.15416, -28.668615, -...   \n",
       "1  [-12.242375, -14.920304999999999, -14.920363, ...   \n",
       "2  [-24.603676, -24.603714, -24.871029, -23.15277...   \n",
       "3  [-22.454607, -23.082819, -23.998013, -23.99805...   \n",
       "4  [-26.006956, -23.164886, -23.164886, -26.89116...   \n",
       "\n",
       "                                              band_2        id inc_angle  \\\n",
       "0  [-27.154118, -29.537888, -31.0306, -32.190483,...  dfd5f913   43.9239   \n",
       "1  [-31.506321, -27.984554, -26.645678, -23.76760...  e25388fd   38.1562   \n",
       "2  [-24.870956, -24.092632, -20.653963, -19.41104...  58b2aaa0   45.2859   \n",
       "3  [-27.889421, -27.519794, -27.165262, -29.10350...  4cfc3a18   43.8306   \n",
       "4  [-27.206915, -30.259186, -30.259186, -23.16495...  271f93f4   35.6256   \n",
       "\n",
       "   is_iceberg  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showcase of data...\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input image dimensions...\n",
    "img_width = 75\n",
    "img_height = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining Epochs, Batch Size & Number of classes...\n",
    "batch_size = 10\n",
    "num_classes = 1\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating the training data bands...\n",
    "Band_1 = np.array([np.array(band).astype(np.float32).reshape(img_height, img_width) for band in training_data[\"band_1\"]])\n",
    "Band_2 = np.array([np.array(band).astype(np.float32).reshape(img_height, img_width) for band in training_data[\"band_2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create 3 bands having Band_1, Band_2 and avg of both...\n",
    "X_train = np.concatenate([Band_1[:, :, :, np.newaxis], Band_2[:, :, :, np.newaxis],((Band_1+Band_2)/2)\n",
    "                          [:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1604, 75, 75, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of train data...\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# The data, shuffled and split between train and test sets...\n",
    "target_train=training_data['is_iceberg']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, target_train, random_state=1, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining shape of input data...\n",
    "input_shape = ( img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creating our model..\n",
    "#Initialising the CNN...\n",
    "model = Sequential()\n",
    "\n",
    "## Step 1 & Step 2 Convolutional and Pooling..\n",
    "#Convolutional Layer 1...\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Convolutional Layer 2...\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Convolutional Layer 3...\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Step 3 Flattening..\n",
    "#Flatten the data for upcoming dense layers...\n",
    "model.add(Flatten())\n",
    "\n",
    "# Step 4 Full connection..\n",
    "#Dense Layer 1...\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Sigmoid Layer...\n",
    "model.add(Dense(num_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compiling the CNN model...\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1203 samples, validate on 401 samples\n",
      "Epoch 1/12\n",
      "1203/1203 [==============================] - 23s 19ms/step - loss: 0.4303 - acc: 0.7988 - val_loss: 0.4612 - val_acc: 0.8080\n",
      "Epoch 2/12\n",
      "1203/1203 [==============================] - 21s 18ms/step - loss: 0.4431 - acc: 0.7880 - val_loss: 0.4442 - val_acc: 0.8155\n",
      "Epoch 3/12\n",
      "1203/1203 [==============================] - 20s 16ms/step - loss: 0.4834 - acc: 0.7938 - val_loss: 0.4665 - val_acc: 0.8254\n",
      "Epoch 4/12\n",
      "1203/1203 [==============================] - 20s 17ms/step - loss: 0.4443 - acc: 0.8121 - val_loss: 0.6181 - val_acc: 0.7307\n",
      "Epoch 5/12\n",
      "1203/1203 [==============================] - 22s 18ms/step - loss: 0.4341 - acc: 0.7997 - val_loss: 0.4442 - val_acc: 0.8504\n",
      "Epoch 6/12\n",
      "1203/1203 [==============================] - 20s 16ms/step - loss: 0.4167 - acc: 0.8071 - val_loss: 0.6870 - val_acc: 0.7456\n",
      "Epoch 7/12\n",
      "1203/1203 [==============================] - 20s 17ms/step - loss: 0.4402 - acc: 0.8121 - val_loss: 0.4640 - val_acc: 0.8379\n",
      "Epoch 8/12\n",
      "1203/1203 [==============================] - 22s 18ms/step - loss: 0.4025 - acc: 0.8180 - val_loss: 0.4837 - val_acc: 0.8155\n",
      "Epoch 9/12\n",
      "1203/1203 [==============================] - 21s 17ms/step - loss: 0.4189 - acc: 0.8155 - val_loss: 0.5244 - val_acc: 0.8429\n",
      "Epoch 10/12\n",
      "1203/1203 [==============================] - 20s 17ms/step - loss: 0.3913 - acc: 0.8263 - val_loss: 0.4489 - val_acc: 0.8204\n",
      "Epoch 11/12\n",
      "1203/1203 [==============================] - 22s 18ms/step - loss: 0.4260 - acc: 0.8138 - val_loss: 0.4253 - val_acc: 0.8379\n",
      "Epoch 12/12\n",
      "1203/1203 [==============================] - 20s 17ms/step - loss: 0.4289 - acc: 0.8146 - val_loss: 0.4064 - val_acc: 0.8603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25b1f582e10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the CNN model with train and test data without denoising...\n",
    "model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(x_test,y_test)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 4s 10ms/step\n",
      "Test loss: 0.406430457298\n",
      "Test accuracy: 0.860349127628\n"
     ]
    }
   ],
   "source": [
    "#Evaluating Test loss and Test Accuracy upon the CNN model...\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Conclusion**   \n",
    "                We may can use more CNN layers and epochs to get the more accuracy and instead of 'rmsprop' may can use \n",
    "                'Adam' optimizer for less data loss or error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "* The Keras Blog and keras.io\n",
    "* Kaggle - Keras Model for Begineers.\n",
    "* becominghuman.ai - Building an image classifier using Deep learning.\n",
    "* tensorflow.org/tutorials/dee_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thanks & Regards**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chandan Shaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cshawdjp1992@gmail.com\n",
    "9002800119"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
